{
  "id": "snapshot_1763036617039_mbzgyaw8k",
  "approvalId": "approval_1763036154132_2pib4lbwg",
  "approvalTitle": "UAT Readiness Requirements",
  "version": 2,
  "timestamp": "2025-11-13T12:23:37.039Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Requirements: UAT Readiness for Beatbox Trainer\n\n## Overview\nMake the Beatbox Trainer app ready for User Acceptance Testing (UAT) by implementing critical missing features, fixing identified issues, adding comprehensive debug capabilities, and establishing a complete testing framework.\n\n## Background\n**Current Status:**\n- ✅ Audio engine working (Oboe with stereo output, mono input)\n- ✅ FFI bridge functional (after regeneration)\n- ✅ Core classification logic implemented\n- ❌ No calibration UI (classifier cannot work without calibration)\n- ❌ No visual feedback during training (users see \"Listening...\" but no responses)\n- ❌ Missing debug logging for troubleshooting\n- ❌ No test coverage metrics\n- ❌ No UAT test scenarios documented\n\n**Root Cause Analysis:**\nThe classification system requires calibration to establish thresholds for KICK, SNARE, and HI-HAT detection. Without calibration data, the classifier cannot identify sounds, resulting in zero feedback to users.\n\n## Goals\n1. **Enable End-to-End User Flow**: Users can calibrate, train, and see real-time feedback\n2. **Debug Visibility**: Comprehensive logging at all system levels (Rust, Dart, UI)\n3. **Test Coverage**: Establish testing infrastructure with >80% coverage\n4. **UAT Documentation**: Clear test scenarios and acceptance criteria\n5. **Production Readiness**: Fix all high-priority issues from audit\n\n## User Stories\n\n### US-1: Calibration Onboarding Flow\n**As a** new user\n**When** I launch the app for the first time\n**Then** I am guided through calibration before accessing training mode\n\n**Acceptance Criteria:**\n- Welcome screen explains calibration purpose\n- Step-by-step instructions for KICK → SNARE → HI-HAT\n- Visual progress indicator (e.g., \"KICK: 7/10 samples\")\n- Audio feedback confirms sample collection\n- Calibration data persists across app restarts\n- Option to recalibrate from settings\n\n**EARS Criteria:**\n- **WHILE** app detects no calibration data exists\n- **WHEN** user launches the app\n- **THEN** the app **SHALL** display calibration onboarding screen\n- **AND** prevent access to training mode until calibration completes\n\n### US-2: Real-Time Classification Feedback\n**As a** user practicing beatbox\n**When** I make a sound into the microphone\n**Then** I see immediate visual feedback showing what sound was detected and timing accuracy\n\n**Acceptance Criteria:**\n- Sound type displayed prominently (KICK/SNARE/HIHAT/UNKNOWN)\n- Color-coded timing feedback (GREEN=on-time, YELLOW=early/late, RED=very off)\n- Timing error shown in milliseconds with +/- indicator\n- Feedback persists for 500ms minimum for readability\n- Smooth transitions between classifications\n- No lag or stuttering in UI updates\n\n**EARS Criteria:**\n- **WHILE** training mode is active and calibration exists\n- **WHEN** onset detector identifies a sound above threshold\n- **THEN** the app **SHALL** classify the sound within 100ms\n- **AND** update the UI with classification result and timing feedback\n- **AND** the feedback **SHALL** remain visible for at least 500ms\n\n### US-3: Debug Mode for Troubleshooting\n**As a** developer or power user\n**When** I enable debug mode\n**Then** I see detailed real-time metrics about audio processing and classification\n\n**Acceptance Criteria:**\n- Toggle for debug mode in settings\n- Real-time audio level meter (RMS visualization)\n- Onset detection events logged with timestamps\n- Feature values displayed (RMS, spectral centroid, flux)\n- Classification confidence scores shown\n- Frame timing and latency metrics\n- Export debug logs to file for analysis\n\n**EARS Criteria:**\n- **WHILE** debug mode is enabled\n- **WHEN** audio engine is running\n- **THEN** the app **SHALL** display:\n  - Current audio input level (RMS)\n  - Onset detection events with timestamps\n  - Extracted feature values for each onset\n  - Classification results with confidence scores\n  - Audio callback timing metrics\n- **AND** log all events to persistent storage\n\n### US-4: Classifier Level Selection\n**As a** user\n**When** I complete basic training\n**Then** I can enable advanced mode (Level 2) for more detailed sound categories\n\n**Acceptance Criteria:**\n- Settings toggle for \"Beginner/Advanced\" mode\n- Beginner: 3 categories (KICK, SNARE, HIHAT)\n- Advanced: 6 categories (Kick, Snare, ClosedHiHat, OpenHiHat, KSnare, Silence)\n- Recalibration required when switching levels\n- UI adapts to show appropriate categories\n- Level preference persists across sessions\n\n**EARS Criteria:**\n- **WHILE** user is in settings screen\n- **WHEN** user toggles difficulty level\n- **THEN** the app **SHALL** update CalibrationState with new level\n- **AND** prompt for recalibration if switching from Level 1 to Level 2\n- **AND** persist level preference to local storage\n\n### US-5: Automated Test Suite\n**As a** developer\n**When** I run the test suite\n**Then** all unit tests, integration tests, and widget tests pass with >80% coverage\n\n**Acceptance Criteria:**\n- Unit tests for all services (AudioService, PermissionService, ErrorHandler)\n- Widget tests for all screens (TrainingScreen, CalibrationScreen, SettingsScreen)\n- Integration tests for audio engine lifecycle\n- Mock implementations for dependencies\n- Coverage reports generated automatically\n- CI/CD pipeline runs tests on every commit\n- All tests complete in <3 minutes\n\n**EARS Criteria:**\n- **WHEN** developer runs `flutter test`\n- **THEN** the test suite **SHALL** execute all test cases\n- **AND** achieve minimum 80% code coverage\n- **AND** complete within 180 seconds\n- **AND** generate HTML coverage report\n\n### US-6: UAT Test Scenarios Documentation\n**As a** QA tester\n**When** I receive the app for UAT\n**Then** I have clear test scenarios covering all critical user paths\n\n**Acceptance Criteria:**\n- Test scenarios document with step-by-step instructions\n- Expected results for each scenario\n- Edge cases and error scenarios included\n- Acceptance criteria for pass/fail\n- Test data and prerequisites specified\n- Known limitations documented\n- Sign-off checklist for UAT completion\n\n**EARS Criteria:**\n- **WHEN** UAT phase begins\n- **THEN** documentation **SHALL** exist containing:\n  - Minimum 15 test scenarios covering all user stories\n  - Clear pass/fail criteria for each scenario\n  - Instructions for reproducing issues\n  - Performance benchmarks (latency, CPU, memory)\n  - Device compatibility matrix\n\n## Non-Functional Requirements\n\n### NFR-1: Performance\n- Audio callback latency: <10ms (P99)\n- UI classification updates: <100ms from onset detection\n- Calibration completion time: <2 minutes for 30 samples\n- App launch time: <3 seconds on mid-range devices\n- Memory usage: <150MB during active training\n- CPU usage: <40% sustained during training\n\n### NFR-2: Reliability\n- No crashes during 30-minute continuous training session\n- Graceful handling of all audio permission states\n- Automatic recovery from audio stream interruptions (calls, notifications)\n- Data persistence survives app crashes\n- Error messages are user-friendly and actionable\n\n### NFR-3: Usability\n- Onboarding flow completable in <3 minutes\n- All buttons and controls have clear labels\n- Feedback is visual and unambiguous\n- Settings are discoverable and intuitive\n- No jargon in user-facing text\n\n### NFR-4: Maintainability\n- Code coverage: >80% (>90% for critical paths)\n- All public APIs documented\n- Architecture diagrams included in docs\n- Dependency injection used throughout\n- No global state beyond necessary singletons\n- Maximum 500 lines per file\n- Maximum 50 lines per function\n\n### NFR-5: Testability\n- All services mockable via interfaces\n- UI components accept dependency-injected services\n- No direct references to FFI or platform channels in UI\n- Test data builders for complex objects\n- Integration test harness for audio engine\n\n## Dependencies\n- **Existing**: oboe-rs, flutter_rust_bridge, permission_handler, tokio\n- **New**: shared_preferences (for calibration persistence), fl_chart (for debug visualizations)\n\n## Constraints\n- Android only (iOS support future work)\n- Minimum Android API 21 (Lollipop)\n- Requires microphone hardware\n- Real-time audio processing (no offline mode)\n- Must work without internet connection\n\n## Success Metrics\n1. **Feature Complete**: All 6 user stories implemented and tested\n2. **Zero Critical Bugs**: No crashes, hangs, or data loss\n3. **Test Coverage**: >80% overall, >90% on critical paths\n4. **UAT Sign-Off**: All test scenarios pass on 3 different Android devices\n5. **Performance**: All NFRs met on Pixel 9a test device\n\n## Out of Scope\n- iOS support\n- Multi-user accounts\n- Cloud sync\n- Social features (sharing, leaderboards)\n- Advanced audio effects (reverb, EQ)\n- Batch calibration import/export\n- Machine learning model customization\n\n## Risks\n1. **Audio Hardware Variability**: Different Android devices may have different mic characteristics\n   - Mitigation: Test on min 3 devices with different chipsets\n2. **Real-Time Performance**: Low-end devices may not meet latency requirements\n   - Mitigation: Establish minimum device specs, graceful degradation\n3. **Calibration UX Complexity**: Users may not understand calibration importance\n   - Mitigation: Clear onboarding with video/animation tutorials\n4. **Test Coverage Gaps**: Hard-to-test real-time audio code\n   - Mitigation: Use mock audio streams, integration test harness\n\n## Glossary\n- **UAT**: User Acceptance Testing - final validation before production release\n- **Onset**: The beginning of a sound event, detected by energy increase\n- **Calibration**: Process of collecting samples to establish classification thresholds\n- **RMS**: Root Mean Square - measure of audio signal amplitude\n- **Spectral Centroid**: \"Center of mass\" of audio spectrum, indicates brightness\n- **Spectral Flux**: Measure of how quickly the audio spectrum changes\n- **FFI**: Foreign Function Interface - Dart-to-Rust communication layer\n",
  "fileStats": {
    "size": 9872,
    "lines": 242,
    "lastModified": "2025-11-13T12:15:47.559Z"
  },
  "comments": []
}