{
  "id": "snapshot_1762959874858_pbg43ptiq",
  "approvalId": "approval_1762959756406_870mky6ag",
  "approvalTitle": "Project Structure Document",
  "version": 2,
  "timestamp": "2025-11-12T15:04:34.858Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Project Structure\n\n## Directory Organization\n\n```\nbeatbox-trainer/\n├── lib/                        # Dart/Flutter UI source code\n│   ├── main.dart              # Application entry point\n│   ├── ui/                    # UI components and screens\n│   │   ├── screens/          # Main app screens\n│   │   ├── widgets/          # Reusable UI widgets\n│   │   └── theme/            # App theming and styles\n│   ├── bridge/               # flutter_rust_bridge generated bindings\n│   │   └── api.dart          # Auto-generated Dart API for Rust calls\n│   └── models/               # Dart data models\n│       ├── classification.dart    # Sound classification results\n│       ├── timing.dart           # Timing feedback models\n│       └── calibration.dart      # Calibration state\n│\n├── rust/                      # Rust audio engine (core DSP)\n│   ├── src/\n│   │   ├── lib.rs            # Library entry point, JNI_OnLoad definition\n│   │   ├── api.rs            # Public API exposed to Dart via flutter_rust_bridge\n│   │   ├── audio/            # Audio I/O layer\n│   │   │   ├── engine.rs     # AudioEngine struct, Oboe callbacks\n│   │   │   ├── metronome.rs  # Sample-accurate metronome generation\n│   │   │   └── buffer_pool.rs # SPSC queue + object pool pattern\n│   │   ├── analysis/         # DSP processing layer\n│   │   │   ├── onset.rs      # Onset detection (spectral flux)\n│   │   │   ├── features.rs   # Feature extraction (centroid, ZCR, etc.)\n│   │   │   ├── classifier.rs # Heuristic rule-based classifier\n│   │   │   └── quantizer.rs  # Timing quantization to metronome grid\n│   │   └── calibration/      # User calibration system\n│   │       ├── state.rs      # Calibration thresholds storage\n│   │       └── procedure.rs  # Calibration workflow logic\n│   └── Cargo.toml            # Rust dependencies\n│\n├── android/                   # Android-specific configuration\n│   ├── app/\n│   │   ├── src/main/\n│   │   │   ├── kotlin/com/ryosukemondo/beatbox_trainer/\n│   │   │   │   └── MainActivity.kt    # System.loadLibrary() init block\n│   │   │   ├── java/io/flutter/plugins/\n│   │   │   │   └── GeneratedPluginRegistrant.java\n│   │   │   ├── AndroidManifest.xml   # Microphone permissions\n│   │   │   └── res/                  # Android resources\n│   │   └── build.gradle.kts          # App-level build config\n│   ├── gradle/                       # Gradle wrapper\n│   ├── build.gradle.kts              # Project-level build config\n│   └── settings.gradle.kts           # Gradle settings\n│\n├── ios/                       # iOS-specific configuration (future)\n├── macos/                     # macOS-specific configuration (future)\n├── windows/                   # Windows-specific configuration (future)\n├── linux/                     # Linux-specific configuration (future)\n│\n├── test/                      # Dart widget and integration tests\n│   ├── widget_test.dart      # Example widget tests\n│   ├── ui/                   # UI component tests\n│   └── bridge/               # Rust bridge integration tests\n│\n├── docs/                      # Technical documentation\n│   └── search.md             # Architecture blueprint (Japanese)\n│\n├── .spec-workflow/            # Spec-workflow MCP server artifacts\n│   ├── steering/             # Steering documents (this file)\n│   ├── specs/                # Feature specifications\n│   └── templates/            # Document templates\n│\n├── pubspec.yaml              # Flutter dependencies\n├── analysis_options.yaml     # Dart static analysis config\n├── .gitignore\n└── README.md\n```\n\n## Naming Conventions\n\n### Files\n\n**Dart/Flutter Layer**:\n- **Screens**: `snake_case.dart` (e.g., `training_screen.dart`, `calibration_screen.dart`)\n- **Widgets**: `snake_case.dart` (e.g., `sound_indicator.dart`, `metronome_controls.dart`)\n- **Models**: `snake_case.dart` (e.g., `classification_result.dart`, `timing_feedback.dart`)\n- **Tests**: `[filename]_test.dart` (e.g., `classification_result_test.dart`)\n\n**Rust Layer**:\n- **Modules**: `snake_case.rs` (e.g., `audio_engine.rs`, `onset_detector.rs`)\n- **Tests**: Inline unit tests using `#[cfg(test)]` modules within each `.rs` file\n- **Integration tests**: `tests/` directory at crate root\n\n**Kotlin/Java Layer**:\n- **Activities**: `PascalCase.kt` (e.g., `MainActivity.kt`)\n- **Package structure**: Follows reverse domain notation (`com.ryosukemondo.beatbox_trainer`)\n\n### Code\n\n**Dart**:\n- **Classes**: `PascalCase` (e.g., `TrainingScreen`, `SoundClassifier`)\n- **Functions/Methods**: `camelCase` (e.g., `startTraining()`, `updateBpm()`)\n- **Constants**: `lowerCamelCase` with `const` keyword (e.g., `defaultBpm = 120`)\n- **Private members**: Prefix with `_` (e.g., `_audioEngine`, `_initializeState()`)\n\n**Rust**:\n- **Structs/Enums**: `PascalCase` (e.g., `AudioEngine`, `BeatboxHit`)\n- **Functions/Methods**: `snake_case` (e.g., `start_audio()`, `detect_onset()`)\n- **Constants**: `UPPER_SNAKE_CASE` (e.g., `DEFAULT_SAMPLE_RATE`, `MIN_ONSET_THRESHOLD`)\n- **Module-private items**: `pub(crate)` visibility for internal APIs\n\n**Kotlin/Java**:\n- **Classes**: `PascalCase` (e.g., `MainActivity`)\n- **Methods**: `camelCase` (e.g., `onCreate()`, `loadLibrary()`)\n- **Constants**: `UPPER_SNAKE_CASE` (e.g., `LIBRARY_NAME`)\n\n## Import Patterns\n\n### Dart Import Order\n1. **Dart SDK imports**: `dart:*` packages\n2. **Flutter framework imports**: `package:flutter/*`\n3. **External package imports**: `package:[other]/*`\n4. **Internal imports**: Relative paths within `lib/`\n5. **Generated bridge imports**: `package:beatbox_trainer/bridge/*`\n\n**Example**:\n```dart\nimport 'dart:async';\n\nimport 'package:flutter/material.dart';\n\nimport 'package:flutter_rust_bridge/flutter_rust_bridge.dart';\n\nimport '../models/classification_result.dart';\nimport '../bridge/api.dart';\n```\n\n### Rust Import Order\n1. **Standard library imports**: `use std::*`\n2. **External crate imports**: Alphabetically sorted\n3. **Internal crate imports**: `use crate::*`\n4. **Module-level imports**: `use super::*` (sparingly)\n\n**Example**:\n```rust\nuse std::sync::Arc;\n\nuse oboe::{AudioInputCallback, AudioOutputStream};\nuse rtrb::RingBuffer;\n\nuse crate::analysis::OnsetDetector;\nuse crate::audio::BufferPool;\n```\n\n### Module Organization\n\n**Rust Crate Structure**:\n- **Public API** (`api.rs`): Only types and functions exposed to Dart (annotated with `#[flutter_rust_bridge::frb]`)\n- **Internal modules**: All implementation details are `pub(crate)` or private\n- **No circular dependencies**: Audio layer → Analysis layer → Calibration layer (one-way dependency flow)\n\n## Code Structure Patterns\n\n### Dart File Organization\n```dart\n// 1. Imports (sorted by category)\nimport 'dart:async';\nimport 'package:flutter/material.dart';\n\n// 2. Class definition with documentation\n/// Widget for displaying real-time classification feedback.\nclass ClassificationWidget extends StatefulWidget {\n  // 3. Public constants\n  static const double defaultSize = 200.0;\n\n  // 4. Constructor and fields\n  const ClassificationWidget({Key? key, required this.stream}) : super(key: key);\n\n  final Stream<ClassificationResult> stream;\n\n  // 5. State creation\n  @override\n  State<ClassificationWidget> createState() => _ClassificationWidgetState();\n}\n\n// 6. State implementation\nclass _ClassificationWidgetState extends State<ClassificationWidget> {\n  // Private fields\n  ClassificationResult? _latestResult;\n\n  // Lifecycle methods\n  @override\n  void initState() { /* ... */ }\n\n  @override\n  void dispose() { /* ... */ }\n\n  // Build method\n  @override\n  Widget build(BuildContext context) { /* ... */ }\n\n  // Private helper methods\n  void _handleResult(ClassificationResult result) { /* ... */ }\n}\n```\n\n### Rust File Organization\n```rust\n// 1. Module documentation\n//! Onset detection using spectral flux algorithm.\n\n// 2. Imports\nuse std::collections::VecDeque;\nuse rustfft::FftPlanner;\n\n// 3. Constants\nconst FFT_SIZE: usize = 256;\nconst THRESHOLD_OFFSET: f32 = 0.1;\n\n// 4. Type definitions\npub struct OnsetDetector {\n    fft_planner: FftPlanner<f32>,\n    prev_spectrum: Vec<f32>,\n    onset_signal: VecDeque<f32>,\n}\n\n// 5. Public API implementation\nimpl OnsetDetector {\n    /// Creates a new onset detector with the specified sample rate.\n    pub fn new(sample_rate: u32) -> Self { /* ... */ }\n\n    /// Processes audio buffer and returns onset timestamps.\n    pub fn process(&mut self, audio: &[f32]) -> Vec<usize> { /* ... */ }\n}\n\n// 6. Private helper methods\nimpl OnsetDetector {\n    fn compute_spectral_flux(&self, spectrum: &[f32]) -> f32 { /* ... */ }\n\n    fn adaptive_threshold(&self) -> f32 { /* ... */ }\n}\n\n// 7. Unit tests\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_onset_detection() { /* ... */ }\n}\n```\n\n### Function/Method Organization\n```rust\n// Input validation first\npub fn classify_sound(features: &Features, thresholds: &Thresholds) -> Result<BeatboxHit, Error> {\n    // 1. Validate inputs\n    if features.centroid <= 0.0 {\n        return Err(Error::InvalidFeatures(\"Centroid must be positive\"));\n    }\n\n    // 2. Core classification logic\n    let hit = if features.centroid < thresholds.kick_centroid {\n        if features.zcr < thresholds.kick_zcr {\n            BeatboxHit::Kick\n        } else {\n            BeatboxHit::Unknown\n        }\n    } else if features.centroid < thresholds.snare_centroid {\n        BeatboxHit::Snare\n    } else {\n        BeatboxHit::HiHat\n    };\n\n    // 3. Clear return point\n    Ok(hit)\n}\n```\n\n## Code Organization Principles\n\n1. **Single Responsibility**:\n   - Each Rust module handles one aspect (audio I/O, onset detection, feature extraction, classification)\n   - Each Dart screen manages one user workflow (training, calibration, settings)\n\n2. **Modularity**:\n   - Rust audio engine is completely independent of Flutter UI\n   - flutter_rust_bridge provides clean abstraction boundary\n   - DSP algorithms are pure functions (no side effects, fully testable)\n\n3. **Testability**:\n   - Rust: Unit tests alongside implementation (`#[cfg(test)]`)\n   - Dart: Widget tests in `test/` directory mirror `lib/` structure\n   - Mock audio data for integration tests (pre-recorded beatbox samples)\n\n4. **Consistency**:\n   - Follow Dart style guide (enforced by `dart format`)\n   - Follow Rust API guidelines (enforced by `clippy`)\n   - Real-time safety rules apply universally to all audio callback code\n\n## Module Boundaries\n\n### Layer Boundaries (Strict Separation)\n\n**UI Layer (Dart) ← Bridge → Engine Layer (Rust)**:\n- **Direction**: UI calls Engine via `flutter_rust_bridge`, Engine sends events to UI via `Stream`\n- **Contract**: UI never accesses audio hardware directly; all audio operations go through Rust API\n- **Rationale**: Maintains real-time guarantees, prevents GC pauses in audio thread\n\n**Engine Layer (Rust) → Audio Hardware (C++ Oboe)**:\n- **Direction**: Rust wraps Oboe via `oboe-rs` bindings\n- **Contract**: Only Rust audio thread touches Oboe callbacks; no direct C++ FFI from Dart\n- **Rationale**: Type safety, memory safety, eliminates manual JNI code\n\n**Audio Thread ← Lock-Free Queue → Analysis Thread**:\n- **Direction**: Audio thread produces buffers, Analysis thread consumes\n- **Contract**: Zero blocking operations in audio thread; all allocations happen in Analysis thread\n- **Rationale**: Real-time safety - prevents xruns and audio glitches\n\n### Feature Boundaries (Soft Separation)\n\n**Core Training vs Calibration**:\n- **Core Training**: Assumes calibration is complete, uses fixed thresholds\n- **Calibration**: Modifies threshold state, isolated to calibration workflow\n- **Shared**: Calibration state struct is shared (read-only during training, read-write during calibration)\n\n**Level 1 (Broad Categories) vs Level 2 (Strict Subcategories)**:\n- **Level 1**: Uses 2 features (centroid, ZCR) with simple rules\n- **Level 2**: Adds 3+ features (flatness, rolloff, envelope) with complex rules\n- **Implementation**: Single `Classifier` struct with difficulty level parameter\n\n### Platform Boundaries\n\n**Android-Specific vs Cross-Platform**:\n- **Android-Specific**: `MainActivity.kt` (JNI initialization), `AndroidManifest.xml` (permissions)\n- **Cross-Platform**: Entire Rust codebase, majority of Dart UI code\n- **Isolation**: Android-specific code limited to `android/` directory; no platform checks in `lib/` or `rust/src/`\n\n## Code Size Guidelines\n\n### File Size Limits (Excluding Comments/Blank Lines)\n- **Maximum lines per file**: 500 lines\n- **Target file size**: 200-300 lines\n- **Action if exceeded**: Split into sub-modules (e.g., `classifier.rs` → `classifier/mod.rs`, `classifier/level1.rs`, `classifier/level2.rs`)\n\n### Function/Method Size\n- **Maximum lines per function**: 50 lines\n- **Target function size**: 10-20 lines\n- **Single Level of Abstraction Principle (SLAP)**: Each function should operate at one level of abstraction\n- **Action if exceeded**: Extract helper functions\n\n### Class/Module Complexity\n- **Maximum methods per struct**: 15 public methods\n- **Cyclomatic complexity**: ≤ 10 per function (enforced via `clippy::cognitive_complexity`)\n- **Nesting depth**: Maximum 4 levels of indentation\n\n### Real-Time Code Constraints (Rust Audio Thread)\n- **Audio callback functions**: ≤ 30 lines (including buffer copy operations)\n- **No heap allocations**: Enforced via code review (no `Vec::push()`, `Box::new()`, etc.)\n- **No locks**: Enforced via code review (no `Mutex`, `RwLock`, `Arc::clone()` in callbacks)\n- **Execution time**: Must complete within `buffer_size / sample_rate` duration (e.g., < 10ms for 512 samples @ 48kHz)\n\n## Documentation Standards\n\n### Rust Documentation (rustdoc)\n- **Public API**: All `pub` items must have `///` doc comments\n- **Complex algorithms**: Include mathematical formulas in doc comments (e.g., spectral centroid formula)\n- **Examples**: Public functions should include `# Examples` section with code snippet\n- **Safety**: Functions with `unsafe` blocks must document invariants\n\n**Example**:\n```rust\n/// Computes spectral centroid (brightness) of the input spectrum.\n///\n/// # Formula\n/// centroid = Σ(f_i * mag_i) / Σ(mag_i)\n///\n/// # Examples\n/// ```\n/// let centroid = compute_centroid(&spectrum, 48000);\n/// assert!(centroid > 0.0 && centroid < 24000.0);\n/// ```\npub fn compute_centroid(spectrum: &[f32], sample_rate: u32) -> f32 { /* ... */ }\n```\n\n### Dart Documentation (dartdoc)\n- **Public widgets**: Document purpose and usage with `///` comments\n- **State management**: Explain lifecycle and state transitions\n- **Stream contracts**: Document what events the Stream emits and when\n\n**Example**:\n```dart\n/// Displays real-time sound classification and timing feedback.\n///\n/// Listens to [classificationStream] and updates UI whenever a new\n/// beatbox sound is detected. Shows sound type (KICK, SNARE, HI-HAT)\n/// and timing accuracy (ON-TIME, EARLY, LATE).\nclass ClassificationWidget extends StatefulWidget { /* ... */ }\n```\n\n### Inline Comments\n- **Complex DSP logic**: Explain \"why\" not \"what\" (code is self-documenting for \"what\")\n- **Real-time constraints**: Flag critical sections with comments like `// REAL-TIME SAFE: No allocations`\n- **Magic numbers**: Always explain hardcoded thresholds (e.g., `// 1500 Hz centroid threshold separates kick from snare`)\n\n### Module-Level Documentation\n- **Purpose**: Each Rust module (`mod.rs` or top of `.rs` file) should have `//!` module doc\n- **Architecture diagrams**: Complex modules (e.g., `audio/`) should reference external docs\n- **Thread safety**: Document which types are `Send`/`Sync` and why\n\n## Project-Specific Patterns\n\n### Error Handling\n\n**Rust**:\n- Use `Result<T, Error>` for fallible operations\n- Audio thread: Log errors but never panic (use `Result` with graceful degradation)\n- Analysis thread: Can panic on unrecoverable errors (will restart thread)\n\n**Dart**:\n- Use `try-catch` for async operations\n- Show user-friendly error messages in UI (never expose stack traces)\n\n### Real-Time Safety Checklist\n\nEvery audio callback function must pass this checklist:\n- [ ] No heap allocations (`Vec::push()`, `Box::new()`, `String::from()`)\n- [ ] No locking primitives (`Mutex`, `RwLock`, `Arc::clone()` with atomic operations)\n- [ ] No blocking I/O (`println!`, file operations, network)\n- [ ] No unbounded loops (all loops must have compile-time known upper bounds)\n- [ ] Execution time is deterministic and < buffer duration\n\n### Flutter-Rust Bridge Patterns\n\n**Async operations**:\n```dart\n// Dart: All Rust calls are async\nfinal result = await rustApi.startAudio(bpm: 120);\n```\n\n**Streaming events**:\n```rust\n// Rust: Return Stream for continuous updates\n#[flutter_rust_bridge::frb]\npub fn classification_stream() -> impl Stream<Item = ClassificationResult> {\n    // Implementation using async channels\n}\n```\n\n**Ownership transfer**:\n```rust\n// Rust: Use Arc for shared state across threads\npub struct AudioEngine {\n    state: Arc<Mutex<State>>,  // Only non-audio thread locks this\n}\n```\n\nThis structure ensures the codebase remains maintainable, testable, and adheres to the strict real-time constraints required for low-latency audio processing.\n",
  "fileStats": {
    "size": 17580,
    "lines": 456,
    "lastModified": "2025-11-12T15:02:20.443Z"
  },
  "comments": []
}