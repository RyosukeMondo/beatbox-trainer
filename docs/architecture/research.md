リアルタイム・ヒューリスティック・ビートボックス・アナライザのためのアーキテクチャ・ブループリント1.1. 序文：ユーザー要件の分解本レポートは、Flutter UIを備えたAndroidアプリケーション「ビートボックス・トレーナー」のための、システムレベルのアーキテクチャ・ブループリントとして機能する。ユーザーからの要件は極めて具体的であり、C++ Oboe -> Rust -> Java/JNI -> Dart/Flutterという4層からなる厳格なネイティブ・スタックを必須としている。まず、このアーキテクチャの選択を検証する。高レベルのDartオーディオプラグイン（1）を意図的に回避し、ネイティブのOboe/Rustコアを選択するという決定は、妥協のないリアルタイム性能を追求するための意図的なものである。高レベルのフレームワークは、ガベージコレクション（5）やブリッジングのオーバーヘッド（6）により、必然的にレイテンシ（遅延）とジッター（タイミングの揺らぎ）を導入する（7）。これらは、精密なリズム・アプリケーションにおいては許容できるものではない。次に、「ヒューリスティックDSP（デジタル信号処理）」という要件に対応する。これは、機械学習（ML）ベースのアプローチ（12）を意識的に排除するものである。このトレードオフは極めて重要である。MLモデル（15）は、多様なユーザーに対して初期状態での高い精度を提供する可能性があるが、それは解釈可能性、CPU負荷、そしてアプリケーションサイズの増大という代償を伴う。一方、ヒューリスティック、すなわちDSPベースのモデル（17）は、構築と調整がより困難であるものの、一度キャリブレーション（調整）されれば、軽量かつ透明であり、リアルタイムのコンテキストにおいて計算論的に高速かつ予測可能である。ユーザーが要求する「段階的な難易度」もまた、ヒューリスティックなアプローチの方が実装が容易である（19）。なぜなら、モデルを再トレーニングすることなく、しきい値のルールをプログラム的に緩和または厳格化（21）できるからである。本レポートは、このシステムを構築するための低レベル・フレームワークを提供する。特に、(1) 4つの言語レイヤー間の「継ぎ目」、(2) リアルタイムのヒューリスティックベース分類のためのDSPロジック、という2つの最も重要な課題に焦点を当てる。1.2. システムレベルのデータフロー図本レポートの指針となる構造として、完全なデータと制御のフローを示す高レベルの図解を以下に記述する。このアーキテクチャは4つの主要なパスによって定義される。制御パス (Dart -> Rust): ユーザーインターフェースからの制御信号（例：「開始」、「BPM設定」）の伝達。Flutter UI -> flutter*rust_bridge -> Rust API -> Rust Audio Engine (Control)オーディオI/Oパス (Native): ネイティブ層で完結する、最も低遅延なオーディオ入出力。Android Mic -> C++ Oboe -> oboe-rs (Input Callback) -> SPSC Ring Buffer -> C++ Oboe -> oboe-rs (Output Callback) -> Android Speaker分析パス (Rust): リアルタイム制約から切り離された、DSP処理の中核。SPSC Ring Buffer -> Rust Analysis Thread -> DSP (Onset -> FFT -> Features) -> Heuristic Classifierフィードバックパス (Rust -> Dart): 分析結果のUIへの返却。Heuristic Classifier -> flutter_rust_bridge (Stream) -> Flutter UI (例: "KICK" - "ON TIME")2.0. 基盤：C++ Oboeとoboe-rsによる低遅延オーディオI/O2.1. オーディオストリームの確立： AudioInputCallbackとAudioOutputCallbackオーディオシステムの核は、GoogleのC++ライブラリであるOboe（22）上に構築される。しかし、C++と直接インターフェースするのではなく、安全でイディオマティックなRustバインディングを提供するoboe-rsクレート（24）を使用する。このクレートは、コンパイル済みのOboeライブラリを内蔵しており（26）、NDKのビルドプロセスを大幅に簡素化する。ユーザーのタスクは、**全二重（full-duplex）**オーディオ、すなわちマイク入力（ビートボックス）とスピーカー出力（メトロノーム）の同時実行を要求する。これを実現するため、oboe::AudioInputCallback（25）とoboe::AudioOutputCallback（24）の2つのトレイトを実装するRustの構造体（例：AudioEngine）を定義する。AudioInputCallbackはon_audio_readyメソッドを提供し、マイクからの生のオーディオデータ（フレーム）をリアルタイムで配信する（27）。AudioOutputCallbackも同様にon_audio_readyメソッドを提供し、こちらはスピーカーへ送信するためのオーディオデータを要求する（24）。2.2. 全二重同期の問題システム設計における最初の重大な落とし穴は、入力ストリームと出力ストリームを単純に独立して開始することである。これは失敗につながる。2つのストリームが同時に開始される保証も、同じオーディオクロックで動作する保証もないため、管理不能なドリフト（ずれ）と同期の問題が発生する（28）。ユーザーはマイク入力をメトロノームのBPMグリッドに対して量子化する必要がある。もし入力ストリームと出力ストリームが同期していなければ、このタスクは原理的に不可能である。従って、Oboeチームが推奨するFullDuplexStreamパターン（28）を採用することが必須である。このアーキテクチャでは、**出力ストリーム（メトロノーム）が「マスター」**となり、**入力ストリーム（マイク）が「スレーブ」**となる。実装の詳細：まず、AudioOutputCallback（30）を持つAudioOutputStream（出力）をオープンする。次に、AudioInputStream（入力）をオープンする。出力コールバック（スピーカー用のon_audio_ready）の内部で、まずメトロノームのクリック音を生成する（詳細はセクション8で後述）。続いて、同じコールバック内で、入力ストリームに対してノンブロッキング読み出し（28）を実行する。このパターンは、入力処理を出力ストリームのハードウェアクロックに効果的に同期させる。これにより、スピーカーに送信するオーディオのすべてのブロックに対して、マイクから対応するブロックを読み出すことが保証され、可能な限り厳密な同期が実現される。2.3. バッファ管理：レイテンシ vs 安定性のチューニングOboeのレイテンシは、バッファパラメータによって直接的に支配される（31）。バーストサイズ（Burst Size）: ハードウェアが一度に処理するフレーム数。これはオーディオ処理における「量子」である（31）。バッファサイズ（Buffer Size）: アプリケーションが保持する総バッファ。これがアプリケーションの知覚レイテンシを決定する（31）。主要なヒューリスティック: Oboeチームは、stream->setBufferSizeInFrames(2 \* stream->getFramesPerBurst())という設定を推奨している（31）。この「ダブルバッファリング」戦略は、最適な出発点である。トレードオフの分析: ユーザーは、より低いレイテンシを達成するために、より小さなバッファサイズを要求することができる。しかし、BufferSizeが低すぎると、CPU負荷のわずかなスパイク（例：OSの通知）がバッファのアンダーラン（バッファが空になること）を引き起こし、「プツッ」という可聴ノイズや「グリッチ」（"xrun"と呼ばれる）を発生させる（31）。推奨事項: 2倍のバーストサイズというデフォルト値から開始する。セクション6で詳述するRustのDSPコードは、次のコールバックまでに常に完了することが証明できるほど高速でなければならない。遅いDSPアルゴリズムをバッファサイズを増やすことで修正しようとしてはならない。それは問題をレイテンシで隠蔽するだけであり、解決にはならない。3.0. リアルタイム・データパイプライン：Rustにおけるロックフリー並行処理3.1. 根本原則：オーディオコールバック内でのアロケーション、ロック、GCの禁止これは、本プロジェクト全体を通して最も重要な単一の原則である（32）。セクション2で定義したOboeのon_audio_readyコールバックは、リアルタイムかつ高優先度のスレッドで実行される（34）。このスレッドの実行が少しでも遅延すれば、即座にオーディオのグリッチとなる。禁止される操作：Mutex::lock(): もしロックが他のスレッドによって保持されていた場合、オーディオスレッドはブロック（待機）し、グリッチを引き起こす。Vec::push()（再アロケーションが発生する場合）: ヒープ上でのメモリ確保は、実行時間が非決定的な、遅い操作である（33）。Box::new(): 明示的なヒープアロケーション。println!（リリースビルドにおいて）: ファイルI/Oはブロッキング操作である。この厳格な制約は、アーキテクチャ上の重要な岐路を示す。FFTやスペクトル特徴量計算といったDSP分析の全容は、複雑すぎ、かつ実行時間が長すぎるため、オーディオコールバックの内部で直接実行することはできない（36）。この結果、2つのスレッドで問題を解決する必要が生じる。スレッドA (AudioThread): Oboeのコールバック。その唯一の仕事は、オーディオバッファ（&[f32]）を受け取り、可能な限り迅速に、処理のための「安全な」場所へ移動させることである。スレッドB (AnalysisThread): 標準的なRustスレッド。その仕事は、スレッドAからのデータを待ち受け、すべての高負荷なDSP処理（FFTなど）を実行し、その結果をUIに送信することである。これら2つのスレッド間の「橋渡し」こそが、本アーキテクチャにおける最も重要な設計箇所となる。3.2. システム設計：SPSCロックフリー・リングバッファAudioThread（プロデューサ）とAnalysisThread（コンシューマ）の間で、ロック（Mutexなど）を使用せずにデータを通信するためには、**単一プロデューサ・単一コンシューマ（SPSC）**のロックフリー・キュー（35）を使用することが絶対条件となる。クレートの分析:rtrb (39): 「リアルタイムセーフ」なオーディオ処理のために明示的に設計されている。**ウェイトフリー（wait-free）**であり、操作の実行時間に厳格な上限があることが保証されている。これは理想的な選択肢である。ringbuf-basedrop (43): 一般的なringbufクレートのフォーク。その主な特徴は、Arcの代わりにbasedropを使用することで、バッファのドロップ（解放）などのデアロケーション（メモリ解放）が、リアルタイムスレッドではなく、非リアルタイムの「コレクタ」スレッドで発生することを保証する点にある（43）。推奨事項: システムはrtrbを使用して構築する。初期化時に、let (mut producer, mut consumer) = RingBuffer::new(capacity)としてキューを作成する。producerはAudioEngine構造体にSendされ、Oboeコールバックの内部で使用される。consumerは新しく生成されるAnalysisThreadにSendされる。3.3. データフロー：Oboeコールバックから分析スレッドへAudioThread (on_audio_ready):Oboeからaudio_data: &[f32]を受け取る。producer.push(audio_data.to_vec())を実行する。...これは間違いである。 to_vec()はヒープアロケーション（メモリ確保）を行う（33）。正しいパターン（オブジェクト・プーリング）: オーディオバッファは**事前確保（pre-allocate）**しておかなければならない。この問題を解決するため、アーキテクチャをさらに洗練させ、2つのrtrbキューを使用する。DATA_QUEUE: rtrb::RingBuffer<Vec<f32>>:満たされたバッファをAudioThreadからAnalysisThreadへ運ぶ。POOL_QUEUE: rtrb::RingBuffer<Vec<f32>>:空になった（使用済み）バッファをAnalysisThreadからAudioThreadへ返却する。AudioThread (on_audio_ready) のループ：Rust// 1. POOL_QUEUEから空のバッファを取得する
let mut buffer = match pool_consumer.pop() {
Ok(buf) => buf,
Err(*) => {
// プールが空。これは処理落ちを意味する。
// オーディオフレームをドロップし、即座にリターンする。
return;
}
};

// 2. データをコピーする（アロケーション無し）
buffer.copy_from_slice(audio_data);

// 3. 満たされたバッファをDATA*QUEUEにプッシュする（アロケーション無し）
match data_producer.push(buffer) {
Ok(*) => {},
Err(_) => { /* DATA_QUEUEが満杯。これも処理落ち。 */ }
}
AnalysisThread のループ：Rustloop {
// 1. DATA_QUEUEから満たされたバッファを取得する（ブロッキング待機）
let mut buffer = match data_consumer.pop() {
Ok(buf) => buf,
Err(_) => { /_ チャンネルが切断された _/ break; }
};

    // 2. 高負荷なDSP処理を実行する（セクション6）
    perform_dsp(&buffer);

    // 3. 空になったバッファをPOOL_QUEUEに返却する
    match pool_producer.push(buffer) {
        Ok(_) => {},
        Err(_) => { /* POOL_QUEUEが満杯。致命的エラーの可能性。 */ }
    }

}
この「プールキュー」パターンこそが、ゼロアロケーションかつリアルタイムセーフなデータ受け渡しを実現する唯一の方法である。これにより、メモリ管理の問題が、解決不可能な「リアルタイム・アロケーション」の問題から、解決可能な「有界のプロデューサ・コンシューマ」の問題へと変換される。4.0. 多言語スタック：C++、Rust、Java、Dartの統合4.1. FFI制御プレーン： flutter_rust_bridgeユーザーはDart UIからRustエンジンを制御（例：BPMの設定、開始/停止）できなければならない。Flutter標準のMethodChannel（45）も選択肢ではあるが、冗長であり、文字列ベースの型付けであり、パフォーマンスも最適ではない。本プロジェクトのスタック（C++ -> Rust -> Java -> Dart）において、flutter_rust_bridgeパッケージ（47）は、Rust -> Dart間の連携に特化して設計されている（48）。このパッケージは、FFI（Foreign Function Interface）とJNI（Java Native Interface）の「グルー（接着剤）」コードをすべて自動生成し、DartとRust間に、型安全で、非同期（async）に対応した、高性能なAPIを提供する（47）。制御パス (Dart -> Rust): fn start_audio(bpm: u32)やfn stop_audio()といったシンプルなRust APIを定義する。flutter_rust_bridgeは、これに対応するDart関数を自動生成する。フィードバックパス (Rust -> Dart): AnalysisThread（セクション3）は、分析結果（例：enum BeatboxHit { Kick, Snare,... }）をUIに送信する必要がある。flutter_rust_bridgeは、Rust関数からStreamを返すことをサポートしている。AnalysisThreadはこのStreamに結果をプッシュし、Dart UIはそれを直接リッスン（listen）する。これはMethodChannelよりも遥かに優れた方法である。4.2. JNIの「落とし穴」： ndk_contextとJNI_OnLoadの初期化ここが、本アーキテクチャ全体で最も重要かつ、最も見落としやすい統合ポイントである。問題の所在: oboe-rsクレート（24）およびその依存クレート（cpalやndk-contextなど）は、機能するためにAndroidのJava仮想マシン（JVM）環境へのアクセスを必要とする。これらは、ndk_context（51）が初期化されていることを前提としている（52）。通常のAndroidアプリの場合: JavaのActivityがSystem.loadLibrary("lib_name")を呼び出す（52）。この呼び出しがトリガーとなり、OSはネイティブライブラリ内のJNI_OnLoadという名前のCシンボル関数を探し出して実行する。この関数こそが、ndk_contextが通常初期化される場所である（52）。Flutterにおける競合: Flutterアプリがネイティブライブラリをロードする際（flutter_rust_bridgeやdart:ffi経由）、ライブラリをロードするのはJava Activityではなく、DartVMである。このプロセスは、JNI_OnLoadのステップをスキップしてしまう（52）。結果: アプリケーションは起動時にandroid context was not initialized（Androidコンテキストが初期化されていません）というパニックでクラッシュする（52）。解決策（52）： この問題は、2つの部分からなる手動の修正を必要とする。1. Kotlin (android/app/src/main/kotlin/.../MainActivity.kt):Flutterがロードする前に、Java側でライブラリを強制的にロードさせる必要がある。MainActivityにinitブロックを追加する（52）。Kotlinpackage com.example.beatbox_trainer

import io.flutter.embedding.android.FlutterActivity

class MainActivity: FlutterActivity() {
init {
// "beatbox_trainer" は Cargo.toml で定義した Rust ライブラリ名
System.loadLibrary("beatbox_trainer")
}
} 2. Rust (lib.rs):KotlinコードがトリガーするJNI_OnLoad関数をRust側で定義する必要がある。Cargo.tomlにjniとndk-contextを依存関係として追加する（52）。Rust#[cfg(target_os = "android")] #[no_mangle] #[allow(non_snake_case)]
pub extern "C" fn JNI_OnLoad(vm: jni::JavaVM, res: \*mut std::os::raw::c_void) -> jni::sys::jint {
use std::ffi::c_void;

    // JavaVMポインタを取得
    let vm_ptr = vm.get_java_vm_pointer() as *mut c_void;

    // ndk_context を初期化
    unsafe {
        ndk_context::initialize_android_context(vm_ptr, res);
    }

    // JNIバージョンを返す
    jni::JNIVersion::V6.into()

}
この「Kotlin init -> System.loadLibrary -> Rust JNI_OnLoad -> ndk_context::initialize」という一連の流れこそが、Flutterアプリケーション内部でoboe-rsを動作させるために必要な「秘密の握手」である。5.0. ヒューリスティック・非ML検出フレームワーク (Part 1)：オンセット検出5.1. 最初の関門：トランジェント（過渡音）の検出セクション3で構築したAnalysisThreadは、オーディオのチャンク（塊）を継続的に受信している。最初のタスクは、サウンドイベント（「オンセット」）がいつ始まったかを検出することである（56）。単純なアプローチ（エネルギーベース）: 最も単純な方法は、信号の実効値（RMS）エネルギーを監視することである（58）。RMSがあるしきい値を超えたら、オンセットとして検出する。なぜこれが失敗するか: この方法は信頼性が低いことで有名である（60）。低エネルギーの「キック」はしきい値を超えないかもしれず、一方で大きなバックグラウンドノイズがしきい値を超えるかもしれない。また、持続音の中での新しいノート（音）の開始を検出するのも苦手である（60）。優れたアプローチ（スペクトルベース）: 信号のスペクトル内容の変化を検出するアルゴリズムを使用しなければならない。パーカッシブなサウンド（打撃音）に対して最も一般的かつ効果的な方法は、**スペクトラル・フラックス（Spectral Flux）**である（61）。5.2. 分析：高信頼なパーカッシブ・オンセットのためのスペクトラル・フラックス理論: スペクトラル・フラックス（SF）は、周波数スペクトルが前のフレームから次のフレームにかけて、どれだけ変化したかを示す尺度である（63）。アルゴリズム:オーディオストリームを、オーバーラップさせた小さなフレーム（例：256サンプル、50%オーバーラップ）に分割する。各フレームについて、FFT（高速フーリエ変換）を計算する。frame_tについて、そのスペクトル強度と、前のフレームframe_t-1のスペクトル強度との間の正の差分を合計する。SF(t) = sum(max(0, FFT_mag(t) - FFT_mag(t-1)))なぜ優れているか: 「ブーン」という持続音は、たとえ音量が大きくても、スペクトルが変化しないためSF ≈ 0となる。一方で、「キック」、「スネア」、「ハイハット」といったパーカッシブな音（64）は、スペクトルに巨大かつ突発的な変化をもたらし、SF値の大きなピークを生成する（56）。これは、我々のアプリケーションが対象とする、トランジェント（過渡音）が豊富な音源にとって理想的である。Rustによる実装: microdspクレートは、spectral_fluxオンセット検出器を内蔵しており、実装を容易にする（65）。あるいは、aubio-rsクレート（66）を使用することもできる。これは、オンセット検出の業界標準であるCライブラリaubioへのバインディングを提供する（68）。推奨事項: 純粋なRustソリューションを優先する場合はmicrodsp（65）を、実績豊富で高度に最適化されたアルゴリズムが必要な場合はaubio-rs（66）を使用する。5.3. ピークピッキングと適応型しきい値スペクトラル・フラックスのアルゴリズムは「オンセット」そのものを出力するわけではなく、値のストリーム（オンセット強度信号、OSSと呼ばれる（57））を出力する。我々は、このストリームから「ピーク（頂点）」を検出（ピック）しなければならない（69）。if (flux_value > static_threshold)のような単純な静的しきい値では、ユーザーが大声でビートボックスする場合と小声の場合に対応できず、不十分である（71）。解決策: **適応型しきい値（Adaptive Thresholding）**を使用しなければならない（69）。実装: 時刻tにおけるしきい値は、OSSの局所的な統計量に基づいて決定されるべきである。例えば、threshold(t) = median(OSS[t-N : t+N]) + offset（70）のように、信号の直近の履歴の中央値（または平均値）にオフセットを加えた値とする。これにより、しきい値が信号の最近の音量レベルに応じて上下し、大きなパッセージでも静かなパッセージでもピークを正確に検出できるようになる。6.0. ヒューリスティック・非ML検出フレームワーク (Part 2)：DSP特徴抽出6.1. オンセット後の分析：「サウンド・オブジェクト」の特性評価セクション5のスペクトラル・フラックス・アルゴリズムが時刻tでオンセットを検出したら、次にそのサウンドを分類しなければならない。そのために、オンセットが検出された時刻から始まる、新しいオーディオデータのウィンドウ（例：512または1024サンプル）を抽出する（72）。この分類用ウィンドウに対してFFTを実行する。この単一のスペクトルから、DSPパラメータの「特徴ベクトル」（73）を抽出する。これこそが、ユーザーが要求した「パラメータ」と「しきい値」の正体である。6.2. 主要なヒューリスティック特徴1. スペクトル・セントロイド（Spectral Centroid）： "明るさ" の尺度定義: スペクトルの「重心」、すなわち加重平均（76）。知覚的相関: 人間が知覚する音の「明るさ」（76）と強く相関する。用途: これが我々の主要な分類器である。低周波の「キックドラム」（79）は非常に低いセントロイド値を持ち、高周波でシビランス（歯擦音）的な「ハイハット」（80）は非常に高いセントロイド値を持つ。「スネア」はその中間に位置する（81）。2. ゼロ・クロッシング・レート（ZCR）： "ノイズ性" の尺度定義: 時間領域の信号がゼロ軸（水平軸）を横切る頻度（73）。知覚的相関: 「ノイズ性」と相関する。トーン性（楽音的）で周期的な音（例：「ブーン」というハム音）はZCRが低い。ノイズ性、無声音、またはシビランス音（例：「シーッ」）はZCRが非常に高い（76）。用途: これは第二の分類器として、サウンドの区別に最適である。「キック」（トーン性）と「スロートベース」（トーン性）はどちらもセントロイドが低いかもしれないが、「ハイハット」（[ts]）（80）はノイズ性によって定義される。高いZCRこそがハイハットの決定的特徴である。3. スペクトル・ロールオフ（Spectral Rolloff）： "歪度" の尺度定義: スペクトルエネルギー全体の特定割合（例：85%）が、それ以下に含まれる周波数ビン（82）。用途: これは「明るさ」を測る、よりロバスト（頑健）な尺度である。高周波の小さなアーティファクトを無視し、エネルギーの大部分がどこに存在するかを示す。4. スペクトル・フラットネス（Spectral Flatness）： "トーン性 vs ノイズ性" の尺度定義: スペクトルの幾何平均と算術平均の比。知覚的相関: 低い値は、スペクトルが「ピーキー」（トーン性）であることを示す。1.0に近い高い値は、スペクトルがフラットで「ホワイト」（ノイズ性）であることを示す。用途: ZCRを補完する。スネアドラム（広帯域ノイズ）は高いフラットネスを持つ。「キック」（単一のトーン）は低いフラットネスを持つ。5. 時間的エンベロープ（Temporal Envelope）： アタック/ディケイ定義: 時間領域における信号の振幅形状。我々が関心を持つのは、アタック（ピーク音量に達する速さ）とディケイ（減衰する速さ）である（83）。用途: サブカテゴリ分類（セクション7.3）において極めて重要。「キック」は鋭いアタックと非常に速い（ダンピングされた）ディケイを持つ。「スネア」は鋭いアタックだが、わずかに長くノイジーなディケイを持つ。「オープン・ハイハット」は鋭いアタックと長いディケイを持つ（81）。6.3. 特徴抽出のためのRustクレート分析これらの特徴を計算するために、Rustクレートが必要である。aus (85): 最も有望なクレート。そのドキュメントには、スペクトル・セントロイド、スペクトル・フラットネス、スペクトル・ロールオフ、スペクトラル・フラックスが明示的に記載されている（86）。この目的のために設計されている。estratto (87): 同様に優れており、スペクトル・セントロイド、フラットネス、ロールオフ、そしてZCRを提供する（87）。synfx-dsp (83): アタック/ディケイの時間的特徴に必要なエンベロープ・フォロワーを提供する。rustfft (89): ausとestrattoは、どちらも内部でrustfftをラッパーとして使用し、基礎となるFFT計算を実行している可能性が高い。7.0. ヒューリスティック・非ML検出フレームワーク (Part 3)：分類とキャリブレーション7.1. ルールベース分類器の構築セクション6で抽出した特徴を使用し、ヒューリスティックなルールセットを構築する（17）。これは、Rustのシンプルなmatch文（または一連のif/else）として実装できる。7.2. 表1：ビートボックス分類のためのヒューリスティック特徴マップ（レベル1：ブロード）目的: この表は、ユーザーが要求した初期の「おおまか」な分類ロジックを提供する。これがヒューリスティック・モデルの中核となる。レベル1の分類器は、初心者にとってもシンプルで、高速、かつロバストでなければならない。そのためには、最も強力な2つの特徴（セントロイドとZCR）のみを使用するのが最善のアプローチである（76）。サウンドカテゴリスペクトル・セントロイド (明るさ)ゼロ・クロッシング・レート (ノイズ性)根拠キックドラムLOW (例: < 1500 Hz)LOW (例: < 0.1)低く、トーン性のある「ブーム」音。（79）スネアドラムMID (例: 1500 Hz - 4000 Hz)MID/HIGH (例: > 0.1)中音域の「スナップ」音または「クラッシュ」音。（81）ハイハットHIGH (例: > 4000 Hz)HIGH (例: > 0.3)高周波でシビランス（歯擦音）的な「ツッ」音。（64）(その他/無音)--オンセット検出のしきい値（セクション5）を通過しない。7.3. 段階的な難易度（レベル2：厳格なサブカテゴリ）ユーザーが「上達するにつれて」要求する「厳格な」サブカテゴリ（19）は、高度な機能である。これは、動的なルールセットを意味する。アプリの「難易度」設定は、分類器がどの特徴を使用するかを変更するべきである。実装：例1：「クローズド・ハイハット」 vs 「オープン・ハイハット」の区別両者ともHIGHのセントロイドとHIGHのZCRを持つため、レベル1のルールでは区別できない（81）。レベル2のルール: 時間的エンベロープ（ディケイ）（83）特徴を追加する。クローズド・ハイハット: ディケイ時間 < 50msオープン・ハイハット: ディケイ時間 > 150ms例2：「キック」 vs 「Kスネア」の区別「Kスネア」（81）は、キックとスネアを同時に鳴らす音である。レベル2のルール: スペクトル・フラットネスを追加する。キック: LOW フラットネス（トーン性）Kスネア: HIGH フラットネス（トーン性のキック + ノイズ性のスネア）この多段階的な、特徴を追加していくアプローチ（21）は、「段階的な難易度」という要件を直接的に実装するものである。7.4. キャリブレーション段階：ユーザーへのヒューリスティック適応問題点: 表1に示したしきい値（例：< 1500 Hz）は、開発者の推測に過ぎない。これらの固定値は、異なる声質（12）や異なるマイク（94）を使用するユーザーには適合せず、失敗する可能性が高い。ヒューリスティック・モデルは、キャリブレーションなしでは脆弱である。解決策: アプリケーションは、初回起動時に「キャリブレーション」ステップを必須としなければならない（95）。実装:アプリ: 「ようこそ。まず『キック』の音を10回出してください。」ユーザー: （10回キック音を出す）アプリ: （セクション6のDSP処理を実行）「認識しました。あなたの『キック』の平均スペクトル・セントロイドは 1250 Hz です。」アプリ: 内部のしきい値をプログラム的に設定する。T_KICK_CENTROID = 1250 _ 1.2 （例：平均値 + 20% の許容範囲）このプロセスを「スネア」と「ハイハット」でも繰り返す。このキャリブレーション・ステップ（70）こそが、ヒューリスティック・モデルの最も重要な部分である。これにより、モデルは開発者の推測に基づいた脆弱なものから、ユーザー固有のロバストな分類器へと変貌する（98）。これこそが、非MLアプローチを実用可能にする鍵である。8.0. トレーナーの中核：サンプル精度メトロノームとリアルタイム量子化8.1. なぜDartレベルのタイマーは失敗するか：ジッター問題「トレーナー」アプリケーションは、安定したBPMグリッドを提供しなければならない。Flutterでの明白な解決策は、Timer.periodic（8）やaudioplayers（7）のようなプラグインを使用することである。これは失敗する。 7や8で文書化されているように、これらの高レベルタイマーは「ランダムな遅延」や最大100msにも及ぶ「ジッター（揺らぎ）」に悩まされる。このジッターは致命的である。ユーザーのタイミングは、「揺らいでいる」時計に対して量子化されることになる。メトロノームが早かっただけなのに、ユーザーは「遅い」とペナルティを受けることになる。Oboeのオーディオパス（セクション2）は低遅延（例：< 20ms（100））である。一方、DartのUIスレッド（6）はそうではない。結果として、低遅延の入力と高遅延のメトロノームという、根本的に不安定なシステムができあがってしまう。8.2. 解決策：Oboeが生成するサンプル精度クリック原則: メトロノームのクリック音は、オーディオ出力と同じリアルタイム・オーディオスレッドで生成されなければならない（101）。実装:セクション2のAudioEngineにおいて、AudioOutputCallback（24）は、sample_rate: u32（サンプルレート）とsamples_per_beat: u64（1拍あたりのサンプル数）という2つの新しいフィールドを持つ。また、永続的なフレームカウンターframe_counter: u64も保持する。on_audio_ready（出力）関数内で、すべてのフレームに対して以下を実行する：Rust// 1拍あたりのサンプル数を計算 (BPMから)
// self.samples_per_beat = (self.sample_rate _ 60) / self.bpm;

// バッファ内の各フレームを処理
for frame in output_buffer.iter_mut() {
if self.frame_counter % self.samples_per_beat == 0 {
// ここがサンプル精度の「拍」のタイミング
// クリック音をバッファにミックスする (加算する)
_frame += self.generate_click_sample();
}
self.frame_counter += 1;
}
generate_click_sample()は、事前にロードされた「クリック音」（例：20msのホワイトノイズや1kHzのサイン波）のサンプルを返すか、その場で生成する。結果: このメトロノームはサンプル精度である。オーディオハードウェアのクロックに対して相対的なジッターはゼロである（103）。これこそが、我々が信頼できる唯一の安定した時計である。8.3. オンセットの量子化：ユーザー入力を内部グリッドに整列これで、サンプル精度の2つのデータが得られた。メトロノームのフレームカウンターとsamples_per_beat（セクション8.2）。ユーザーのオンセットが検出されたタイムスタンプt_onset（セクション5）。量子化ロジック（AnalysisThread内）：オンセットがt_onset（総サンプル数）で検出されたとする。beat_error = (t_onset % samples_per_beat)このbeat_error（拍の頭からのズレ）を分類することができる（105）。Rustlet error_ms = (beat_error as f64 / sample_rate as f64) _ 1000.0;
let tolerance_ms = 50.0; // 50msの許容範囲

if error_ms < tolerance_ms {
// "On-Beat"
} else if error_ms > (samples_per_beat_ms - tolerance_ms) {
// "Early" (次の拍に近すぎる)
} else {
// "Late"
}
これで、「トレーナー」としてのフィードバック・ループが完成する。アプリケーションは、証明可能なほど安定した低遅延クロックに対して、ユーザーのタイミングを正確に測定できるようになった（108）。9.0. 中核分析：検出品質とリアルタイム性能のバランス9.1. 実践における時間-周波数 不確定性原理本セクションは、ユーザーのクエリの中核である、DSPにおける最も根源的なトレードオフに取り組む。競合: DSPの「不確定性原理」は、完璧な時間分解能と完璧な周波数分解能を同時に得ることはできない、と定めている（111）。オンセット検出（セクション5）： 高い時間分解能を必要とする。サウンドがいつ始まったかを正確に知る必要がある。これには小さなFFTウィンドウ（例：256サンプル）が必要である（111）。分類（セクション6）： 高い周波数分解能を必要とする。100Hzの「キック」と200Hzの「スネア」を区別する必要がある。これには大きなFFTウィンドウ（例：1024または2048サンプル）が必要である（115）。トレードオフ:もし小さなウィンドウ（例：256サンプル）をすべての処理に使用した場合：タイミング（オンセット）は正確だが、スペクトル・セントロイドの計算は「ぼやけ」て不正確になる（118）。結果として、サウンドを誤分類する。もし大きなウィンドウ（例：2048サンプル）をすべての処理に使用した場合：分類は正確だが、オンセット検出が「ぼやけ」てしまう（112）。「イベント」が2048サンプル全体で平均化されてしまい、すべてのタイミング精度が失われる。9.2. 提案する解決策：マルチ解像度 STFT 戦略この問題の解決策は、どちらか一方を選ぶことではない。両方を実行しなければならない（119）。AnalysisThreadは、2つの独立したDSPパイプラインを順次実行する。パイプライン 1： 「オンセット」STFT（リアルタイム、継続的）FFTサイズ: 小（例：256サンプル）（112）ホップサイズ: 小（例：64サンプル、75%オーバーラップ）アルゴリズム: スペクトラル・フラックス（セクション5）目的: 入力されるすべてのオーディオに対して継続的に実行する。その唯一の仕事は、オンセットを検出し、その正確なタイムスタンプ（t_onset）を報告することである（57）。FFTクレート: microfft（123）またはrustfft（89）が使用可能。microfftは実数値信号に最適化されており、高速である可能性がある（124）。パイプライン 2： 「分類」FFT（イベントトリガー型）FFTサイズ: 大（例：1024サンプル）（117）ホップサイズ: N/A（単一の変換）アルゴリズム: t_onsetがこのパイプラインをトリガーする。t_onsetから始まる1024サンプルのオーディオウィンドウを切り出す（72）。目的: 高解像度のFFTを1回実行する。このスペクトルを使用して、分類のためだけにスペクトル・セントロイド、ZCRなどを計算する（セクション6）。結論: この2段階のマルチ解像度戦略（119）こそが、高品質な検出（大きなウィンドウ）とリアルタイム性能（正確なタイミング）という、ユーザーの相反する要求を満たす唯一の方法である。これは、「いつ（When）」の問題と「何を（What）」の問題を明確に分離する。10.0. 最終アーキテクチャ・レビューと推奨事項10.1. 完全なデータフローの概要本アーキテクチャの全体像を、ユーザーの口から発せられた単一のビートボックス・サウンドがUIのフィードバックに至るまでの流れを追跡することで、総括する。UI (Dart): ユーザーが「開始」を押し、BPMを120に設定する。flutter_rust_bridge（48）がrust_api::start_audio(120)を呼び出す。ネイティブ初期化 (Java/Rust): MainActivity.ktのinitブロック（52）がSystem.loadLibraryを呼び出し、それがRustのJNI_OnLoad関数（52）をトリガーし、ndk_context（51）の初期化に成功する。Rustエンジン:AnalysisThreadを起動する。rtrbのオブジェクトプールとSPSCキュー（39）を初期化する。oboe-rs（24）を初期化し、全二重ストリーム（29）を開く。AudioOutputCallback（26）が開始され、フレームのカウントを始める。frame_Nにおいて、メトロノームのクリック音を合成し、バッファにミックスする。同時に、入力ストリームに対するノンブロッキング読み出しを実行する。ユーザーのアクション: ユーザーがクリック音の後に「キック」音をビートボックスする。AudioThread (リアルタイム):「キック」音のオーディオがAudioInputCallbackバッファに到着する。コールバックはPOOL_QUEUEから空のVecをpopし、「キック」データを（アロケーション無しで）コピーし、満たされたVecをDATA_QUEUEにpushする（39）。この操作全体がロックフリーかつリアルタイムセーフである。AnalysisThread (非リアルタイム):DATA_QUEUEから「キック」バッファをpopする。パイプライン1（オンセット）（セクション9.2）を実行する。スペクトラル・フラックス（65）アルゴリズムが、t_onsetでピークを発見する（57）。パイプライン2（分類）（セクション9.2）をトリガーする。t_onsetから始まる1024サンプルのウィンドウに対して実行する。特徴量を計算する：centroid = 1100Hz, zcr = 0.08（セクション6）。ヒューリスティック・ルール（セクション7）を適用する：(1100Hz < T_KICK_CENTROID) かつ (0.08 < T_KICK_ZCR)。結果：BeatboxHit::Kick。量子化（セクション8.3）を適用する：(t_onset % samples_per_beat)の値は15msに相当。結果：Timing::Late。空になったバッファをPOOL_QUEUEに返却する。フィードバックループ (Rust -> Dart):AnalysisThreadは、結果(BeatboxHit::Kick, Timing::Late)をflutter_rust_bridgeのStream（48）にプッシュする。UI (Dart): Flutter UIのStreamBuilderがイベントを受け取り、即座にリビルドされ、「KICK」と「LATE」を表示する。10.2. 最終推奨事項本アーキテクチャは複雑ではあるが、証明可能なほど堅牢である。リアルタイムのオーディオスレッドを、すべての非リアルタイム操作（アロケーション、ロック、高負荷な計算）から正しく分離し、ユーザーの核となる制約条件をすべて満たしている。プロジェクトの成功のために、以下の3つのコンポーネントが最も重要であり、省略不可能である。JNI_OnLoadによる初期化（セクション4.2）： これがなければ、oboe-rsはFlutter内で起動すらしない。SPSC「プールキュー」（セクション3.3）： リアルタイムスレッドの安全性を保証する、唯一のゼロアロケーション・データ転送メカニズムである。ユーザー・キャリブレーション（セクション7.4）： これがなければ、ヒューリスティック・モデルは開発者以外のユーザーに対して機能しない。最後に、**マルチ解像度STFT戦略（セクション9.2）**は、「品質 vs パフォーマンス」のトレードオフを解決する鍵であり、より単純な単一FFTモデルよりも、このアプローチを強く推奨する。これにより、正確なタイミング（オンセット）と正確な分類（特徴）という、相反する要求を両立させることが可能となる。
