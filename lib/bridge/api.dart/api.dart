// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.11.1.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import 'analysis.dart';
import 'analysis/classifier.dart';
import 'analysis/quantizer.dart';
import 'calibration/progress.dart';
import 'error.dart';
import 'frb_generated.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';

// These types are ignored because they are neither used by any `pub` functions nor (for structs and enums) marked `#[frb(unignore)]`: `AudioMetrics`, `OnsetEvent`
// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `clone`, `fmt`, `fmt`
// These functions are ignored (category: IgnoreBecauseExplicitAttribute): `audio_metrics_stream`, `onset_events_stream`

/// Initialize and greet from Rust
///
/// This is a simple stub function to verify flutter_rust_bridge integration works.
/// Returns a greeting message.
///
/// # Returns
///
/// * `Result<String>` - Success message or error
String greet({required String name}) =>
    RustLib.instance.api.crateApiGreet(name: name);

/// Get the version of the audio engine
///
/// Returns the current version of the beatbox trainer audio engine.
///
/// # Returns
///
/// * `Result<String>` - Version string
String getVersion() => RustLib.instance.api.crateApiGetVersion();

/// Start the audio engine with specified BPM
///
/// Initializes the audio engine, starts full-duplex audio streams with Oboe,
/// spawns the analysis thread, and begins metronome generation.
///
/// # Arguments
/// * `bpm` - Beats per minute (typically 40-240)
///
/// # Returns
/// * `Ok(())` - Audio engine started successfully
/// * `Err(AudioError)` - Error if initialization fails
///
/// # Errors
/// - Audio streams cannot be opened (device busy, permissions denied)
/// - Audio engine already running (call stop_audio first)
/// - Invalid BPM value (must be > 0)
/// - Lock poisoning on shared state
Future<void> startAudio({required int bpm}) =>
    RustLib.instance.api.crateApiStartAudio(bpm: bpm);

/// Stop the audio engine
///
/// Stops audio streams, shuts down the analysis thread, and releases resources.
/// Safe to call even if audio engine is not running.
///
/// # Returns
/// * `Ok(())` - Audio engine stopped successfully or was not running
/// * `Err(AudioError)` - Error if shutdown fails or lock poisoning
Future<void> stopAudio() => RustLib.instance.api.crateApiStopAudio();

/// Set BPM dynamically during audio playback
///
/// Updates the metronome tempo. Note: This currently requires audio engine restart
/// to maintain real-time safety guarantees.
///
/// # Arguments
/// * `bpm` - New beats per minute (typically 40-240)
///
/// # Returns
/// * `Ok(())` - BPM updated successfully
/// * `Err(AudioError)` - Error if update fails
///
/// # Errors
/// - Audio engine not running
/// - Invalid BPM value (must be > 0)
/// - Lock poisoning on audio engine state
Future<void> setBpm({required int bpm}) =>
    RustLib.instance.api.crateApiSetBpm(bpm: bpm);

/// Stream of classification results
///
/// Returns a stream that yields ClassificationResult on each detected onset.
/// Each result contains the detected sound type (KICK/SNARE/HIHAT/UNKNOWN)
/// and timing feedback (ON_TIME/EARLY/LATE with error in milliseconds).
///
/// The stream is active while the audio engine is running and emits results
/// continuously until the audio engine is stopped.
///
/// # Parameters
/// * `sink` - StreamSink for forwarding classification results to Dart
///
/// # Usage
/// ```dart
/// final stream = classificationStream();
/// await for (final result in stream) {
///   print('Sound: ${result.sound}, Timing: ${result.timing}');
/// }
/// ```
///
/// # Implementation
/// Uses the StreamSink pattern supported by flutter_rust_bridge:
/// - Rust function accepts `StreamSink<T>` parameter
/// - Dart receives `Stream<T>` return type
/// - Function can hold sink and emit results asynchronously
Stream<ClassificationResult> classificationStream() =>
    RustLib.instance.api.crateApiClassificationStream();

/// Start calibration workflow
///
/// Begins collecting samples for calibration. The system will detect onsets
/// and extract features without classifying. Collect 10 samples per sound type.
///
/// Calibration sequence: KICK → SNARE → HI-HAT
///
/// # Returns
/// * `Ok(())` - Calibration started
/// * `Err(CalibrationError)` - Error if calibration cannot start
///
/// # Errors
/// - Calibration already in progress
/// - Lock poisoning on calibration procedure state
Future<void> startCalibration() =>
    RustLib.instance.api.crateApiStartCalibration();

/// Finish calibration and compute thresholds
///
/// Completes the calibration process, computes thresholds from collected samples,
/// and updates the global CalibrationState used by the classifier.
///
/// # Returns
/// * `Ok(())` - Calibration completed successfully
/// * `Err(CalibrationError)` - Error if calibration incomplete or invalid
///
/// # Errors
/// - Calibration not in progress
/// - Insufficient samples collected (need 10 per sound type)
/// - Sample validation failed (out of range features)
/// - Lock poisoning on calibration state
Future<void> finishCalibration() =>
    RustLib.instance.api.crateApiFinishCalibration();

/// Stream of calibration progress updates
///
/// Returns a stream that yields CalibrationProgress as samples are collected.
/// Each progress update contains the current sound being calibrated and
/// the number of samples collected (0-10).
///
/// # Returns
/// Stream\<CalibrationProgress\> that yields progress updates
///
/// # Usage
/// ```dart
/// final stream = calibrationStream();
/// await for (final progress in stream) {
///   print('${progress.currentSound}: ${progress.samplesCollected}/10');
/// }
/// ```
///
/// # Implementation
/// Uses the StreamSink pattern supported by flutter_rust_bridge:
/// - Rust function accepts `StreamSink<T>` parameter
/// - Dart receives `Stream<T>` return type
/// - Function can hold sink and emit results asynchronously
Stream<CalibrationProgress> calibrationStream() =>
    RustLib.instance.api.crateApiCalibrationStream();

/// Load calibration state from JSON
///
/// Restores a previously saved calibration state from JSON string.
/// This allows users to skip calibration on subsequent app launches.
///
/// # Arguments
/// * `json` - JSON string containing serialized CalibrationState
///
/// # Returns
/// * `Ok(())` - Calibration state loaded successfully
/// * `Err(CalibrationError)` - Error if deserialization fails or lock poisoning
///
/// # Errors
/// - JSON deserialization error (invalid format)
/// - Lock poisoning on calibration state
///
/// # Usage
/// ```dart
/// try {
///   await loadCalibrationState(jsonString);
///   print('Calibration loaded successfully');
/// } catch (e) {
///   print('Failed to load calibration: $e');
/// }
/// ```
Future<void> loadCalibrationState({required String json}) =>
    RustLib.instance.api.crateApiLoadCalibrationState(json: json);

/// Get current calibration state as JSON
///
/// Retrieves the current calibration state serialized to JSON string.
/// This JSON can be saved to persistent storage and restored later using
/// `load_calibration_state`.
///
/// # Returns
/// * `Ok(String)` - JSON string containing serialized CalibrationState
/// * `Err(CalibrationError)` - Error if serialization fails or lock poisoning
///
/// # Errors
/// - JSON serialization error (should be rare)
/// - Lock poisoning on calibration state
///
/// # Usage
/// ```dart
/// try {
///   final jsonString = await getCalibrationState();
///   // Save jsonString to SharedPreferences
/// } catch (e) {
///   print('Failed to get calibration state: $e');
/// }
/// ```
Future<String> getCalibrationState() =>
    RustLib.instance.api.crateApiGetCalibrationState();
